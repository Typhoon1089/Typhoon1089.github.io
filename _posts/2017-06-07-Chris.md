---
layout: post
title: Báo cáo phiên họp lần thứ 118 của MPEG tại Australia
subtitle: ... available on May 30, 2017
image: /img/mpeglogo.gif
tags: [Expert]
---

Bài viết này được lược dịch từ bài báo gốc của giáo sư Christian. Thông tin chi tiết có thể thấy ở [[link](https://multimediacommunication.blogspot.jp/2017/05/mpeg-news-report-from-118th-meeting.html)].

Phiên họp MPEG lần 118 thảo luận các chủ đề sau:

* **Các Coded Representation của Immersive Media (MPEG-I):** các item đã được chấp nhận và call for test data
* **Định dạng ứng dụng đa phương tiện thông thường (CMAF):** FDIS
* **Chuẩn video tiếp theo (tốt hơn HEVC):** call for thí nghiệm cho các chuẩn nén tốt hơn HEVC và các verification tests cho bản mở rộng dành cho Screen Content của HEVC. 

## Các Coded Representation của Immersive Media (MPEG-I)

MPEG đã phát triển chuẩn ISO/IEC 23090 với tên gọi MPEG-I tập trung vào immersive applications. Chuẩn mới hướng tới panoramic video với 2D/3D audio. Hiện tại, chuẩn sẽ bao gồm các phần quan trọng như:
(pt.1) bản báo cáo mô tả phạm vi của chuẩn mới và các trường hợp được sử dụng.
(pt.2) một định dạng cho dữ liệu đa phương tiện nhiều chiều (được biết đến như OMAF) để giải quyết những yêu cần cấp thiết của công nghiệp.
(pt.3) immersive video, một mục tiêu cho phiên bản tiếp theo của HEVC.
(pt.4) immersive audio, một mục tiêu cho phiên bản tiếp theo của 3D audio.
(pt.5) liên quan đến point cloud compression. Chuẩn point cloud compression tập trung vào nén có mất mát cho point cloud (đám mây điểm) trong thông tin thời gian thực (real-time communication), sáu chiều thực tại ảo (6 Degres of Freedom - 6 DoF Virtual reality), và dynamic mapping cho ứng dụng xe tự hành, thám hiểm văn hóa hoặc tương tự. Phần 2 của chuẩn liên quan đến OMAF, format mà tác giả đã diễn tả ở bài viết trước đó.
 
MPEG cũng đã có nhóm nghiên cứu Ad-hoc (Ad-hoc Group) để đánh giá chất lượng immersive media với các nhiệm vụ sau đây: 1. Công bố tài liệu về VR QoE requirements; 2. Thu thập dữ liệu (material) với các video đa chiều và tín hiệu âm thanh; 3. Nghiên cứu các phương pháp để đánh giá cảm nhận và phản ứng của người dùng với một video VR (VR stimuli); 4. Phát triển một phương pháp đánh giá immersive media, bao gồm cả trường hợp đồng thời có cả video và audio. AhGs là mở rộng cho tất cả mọi người sử dụng mailing list [[join here]](ttps://lists.aau.at/mailman/listinfo/immersive-quality). Một điều thú vị là, nhóm nghiên cứu Immersive Media chung Qualinet-VQEG (JQVIM) được công bố gần đây cũng có cùng mục tiêu và VR Industry Forum (VRIF) đã call for VR360 content. Có thể thấy sự cần thiết của một bộ dữ liệu (dataset), giống như bộ dữ liệu mà tác giả đã tạo ra cho MPEG-DASH trước đó khá lâu.

[JQVIM](https://www3.informatik.uni-wuerzburg.de/qoewiki/qualinet:imex:jqvim) được tạo ra như là một nhóm của QUALINET trong nỗ lực nghiên cứu Immersive Media Experiences ([IMEx](https://www3.informatik.uni-wuerzburg.de/qoewiki/qualinet:imex)), tập trung vào việc giúp người dùng cảm nhận được là một phần trong media đặc biệt, điều đó sẽ giúp nâng cao chất lượng cảm nhận. Mục tiêu chính của nhóm là tạo ra dataset và tools (cả hardware/software), đánh giá chất lượng chủ quan (subjective quality evaluations), lĩnh vực nghiên cứu và check chéo bao gồm một tổ chức lý thuyết liên quan tới dữ liệu.

## Common Media Application Format (CMAF)

Bản nháp cuối cùng của chuẩn FDIS đã được tạo ra ở cuộc gặp thứ 118, nó bao gồm cả quá trình phát triển trước đó của chuẩn. Tai thời điểm này, các nước chỉ có thể vote Có/Không; sự thay đổi về khía cạnh câu chữ là được phép trước khi chuẩn quốc tế được sử dụng. Mục tiêu của CMAF là định nghĩa một định dạng đơn lể cho truyền dẫn và lưu trữ của segmented video bao gồm cả audio/video formats, subtitiles, và encrytion -- nó được đưa tới từ ISO Base Media File Format (ISOBMFF). Bởi vì định dạng này là một tổ hợp của rất nhiều chuẩn MPEG, nó được đề cập như là một application format (AS), cái lấy chuẩn và format chính và gắn chúng với nhau cho một ứng dụng cụ thể. 

Chuẩn CMAF hướng tới dynamic adaptive streaming (qua -- nhưng không giới hạn -- HTTP) nhưng chỉ tập trung vào media format và xuất ra một định dạng manifest. Do đó, chuẩn CMAF sẽ phù hợp với các chuẩn khác như MPEG-DASH và HLS. Thực tế, HLS đã được mở rộng để hỗ trợ 'fragmented MP4' cái mà tác giả đã minh họa và nó đã được giải thích như là mội bước hướng tới sự kết hợp của MPEG-DASH và HLS; ít nhất là trên phương diện segment format. Sự truyền dẫn của CMAF content với DASH sẽ được đề cập ở part 7 của MPEG-DASH, nó sẽ cơ bản bao gồm mapping của CMAF concepts vào DASH terms.

Từ quan điểm nghiên cứu, các nhà nghiên cứu quan tâm tới việc khám phá CMAF concepts có khả năng giải quyết các yêu cầu của công nghiệp như thế nào, đặc biệt là trong context của low-latency streaming.

## Tiếp theo HEVC...

Call cho bằng chứng (Call for evidence - CfE) cho chuẩn mã hóa video với khả năng cao hơn HEVC đã được công bố gần đây và được gửi tới các nhà nghiên cứu, những người có các công nghệ nén tốt hơn hiện tại, cả cho video định dạng hiện tại hay cho các phần khác như HDR/WCG hay 360-degree (VR) video. Các trường hợp test (test case) được định nghĩa cho SDR, HDR, hay 360 độ content. Bản kêu gọi này được đưa ra bởi cả ISO/IEC MPEG và ITU-T SG16/Q6 (VCEG). Việc đánh giá các trả lời nhận được sau CfE được lên kế hoạch vào tháng 7, 2017 và phụ thuộc vào đầu ra của CfE, ban điều hành của Joint Video Exploration Team (JVET) của MPEG và VCEG đưa ra Draft Call cho các đê xuất và cuối hội nghị tháng 7 này.

Cuối cùng, các test kiểm chứng được thực hiện cho phân mở rộng Screen Content Coding (SCC) của HEVC chỉ ra hiệu suất đáng chủ ý. Screen content là một video có chứa tỉ lệ đáng kể các rendered graphics, text, và animation hơn là chỉ các cảnh được capture bởi camera. Với các cảnh bao gồm số lượng đáng kể text và graphics, các test đã chỉ ra các lợi ích chính của chuẩn nén mới so với cả chuẩn AVC và phiên bản cũ của chuẩn HEVC mà không có tính năng hỗ trợ SCC.

Câu hỏi liệu có và như thế nào codecs mới giống như (hoặc tốt hơn) HEVC cạnh tranh với [AVI]({{site.url}}/2017-04-30-Bitmovin/) phụ thuộc vào các nhà nghiên cứu và phát triển. Điều này cũng được thảo luận trong một bài báo ở [đây](http://ieeexplore.ieee.org/document/7906321/) nhưng hiếm óc các so sánh khách quan vì có quá nhiều sự khác biệt về công cụ và tham số. Một khía cạnh quan trọng luôn cần được quan tâm là một nghiên cứu thông thường so sánh implementation cụ thể của một định dạng mã hóa mà không phải một chuẩn thì không được định nghĩa cơ bản, và chỉ bitstream syntax được định nghĩa hoàn toàn decoders.

Các tài liệu công khai từ phiên họp thứ 118 của MPEG có thể được tìm thấy ở  [đây](http://mpeg.chiariglione.org/meetings/118) (cuộn chuột xuống dưới để thây). Phiên họp tiếp theo của MPEG sẽ được tổ chức ở Torino, Italy, 17-21 tháng 7 năm 2017. 
