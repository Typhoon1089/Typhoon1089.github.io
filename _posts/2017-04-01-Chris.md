---
layout: post
title: Các hoạt động liên quan đến việc chuẩn hóa VR/360 Streaming
image: /img/mpeg-vr-major-interfaces.png
tags: [Expert]
---

Bài báo gốc có thể thấy ở [[link](https://multimediacommunication.blogspot.jp/2017/04/vr360-streaming-standardization-related.html)]. Các khái niệm không được dịch: focal distortion, VR sickness, lens/refraction, head-mounted displays

Khái niệm Universal media access (UMA) được đưa ra vào cuối nhưng năm 1990 đầu những năm 2000, và hiện tại đã thành sự thật. Chúng ta có thể dễ dàng tạo và chia sẻ media content ở bất cứ đâu, bất cứ lúc nào với rất nhiều thiết bị khác nhau. Những dịch vụ thời gian thực (tức là streaming video/audio) thường được triển khai trên nền tảng Internet. Chúng đang chiếm hơn 70% Internet traffic khu vực Bắc Mỹ (vào ban đêm). Con số này sẽ đạt tới 80% vào cuối năm 2020. Gần đây, một bước tiến dài về mặt công nghệ là Adaptive Streaming over HTTP đã dẫn tới chuẩn MPEG-DASH.

Bước tiến quan trọng tiếp theo của Adaptive streaming nhiều khả năng sẽ liên quan tới Virtual reality (VR) và omnidirectional streaming. Hệ sinh thái (streaming ecosystems) cho hai dạng streaming mới này được minh họa như hình dưới đây (xem thêm MPEG-I):

<div class="imgcap">
 <img src ="/img/mpeg-vr-major-interfaces.png" align = "center" width = "800">
 <div class = "thecap"> Hình 1: VR interfaces </div>
</div>

Khác với video dạng cũ, omnidirectional video (ODV) cho phép người dùng thay đổi hướng nhìn khi xem một đoạn video. Những video content đặc biệt dạng này có thể được xử lý bởi các thiết bị khác nhau từ smart phone và máy tính để bàn cho đến các thiêt bị head-mounted displays (HMD) như Oculus Rift, Samsung Gear VR, HTC Vive. Khi sử dụng HMD, hướng nhìn có thể được thay đổi khi chúng ta quay đầu. Trên smart phones/tablets, hướng nhin có thể được thay đổi băng cách "chạm" (touch interaction) hoặc bằng cách di chuyển smart phones/tablets với sự trợ giúp của các sensors. Còn với máy tính để bàn, chuột và bàn phím có thể được sử dụng điều khiển góc nhìn. 

Việc streaming các ODV content hiện tại được thực hiện một cách sơ khai, nó giống như streaming toàn bộ cảnh 360 với chất lượng cố định và không quan tâm góc nhìn của người dùng.

## Hiện tại, có một vài hoạt động liên quan đễn chuẩn đang được tiến hành

Forum công nghiệp cho VR (**VR-IF**) đã được mở với mục tiêu phổ biến VR, bao gồm các nhóm nhỏ liên quan tới yêu cầu (requirements), hướng dẫn (guidlines), interoperability, truyền dẫn (communications), và phối hợp (liaison). Tuy VR-IF chỉ mới bắt đầu nhưng nó được kỳ vọng sẽ nhanh chóng phát triển như DASH-IF trước kia.

**QUALINET**, một tố chức châu âu (European network), quan tâm đến Quality of Experience (QoE) của dịch vụ đa phương tiện. Liên quan đến VR/360-degree, tổ chức này tập trung vào "Immersive Media Experiences (IMEx)" và bất cứ ai cũng có thể đóng góp ý kiến cho QUALINET. QUALINET cũng hợp tác tiêu chuẩn hóa và giúp thực hiện các thí nghiệm đánh giá QoE. Ví dụ, có rất nhiều thí nghiệm đã được thực hiện bởi QUALINET trong suốt quá trình phát triển chuẩn MPEG-H High Efficiency Video Coding (HEVC).

**JPEG** bắt đầu khởi động dự án Pleno tập trung vào ảnh. Tác giả đã trình bày trước đó về MPEG-I, như là một phần của báo cáo về hội nghị MPEG [link]({{site.url}}/2017-03-31-Chris-Feb-10), sẽ bao gồm 5 phần. Phần đầu sẽ bao gồm các báo cáo kỹ thuật diễn tả scope, use cases và applications. Nên nhớ các báo cáo kĩ thuật này thông thường là miễn phí. Phần thứ hai tập trung vào Omnidirectiona media application format (OMAF) giải quyết những yêu cầu cấp thiết của industry về chuẩn mới. Phần thứ ba và bốn lần lượt tập trung vào immersive video và immersive audio. Cuối cùng, phần năm sẽ bao gồm các đặc tả về mã hóa trên cloud. OMAF là một phần trong bước đầu tiên của chuẩn, liên quan tới immersive media. Nó sẽ được chuẩn hóa và công bố vào cuối năm 2017 trong khi các phần khác sẽ được cân nhắc vào thời điểm khoảng 2020. Cho đến nay, Committee draft về OMAF bao gồm (i) qeuirectangular projection format, (ii) metadata và interoperable rendering cho 360-degree monoscopic/stereoscopic audio-visaul data, (iii) định dạng lưu trữ dựa trên ISO base media file format (ISOBMFF/mp4), và (iv) các codec liên quan: MPEG-H High Efficiency Video Coding (HEVC) và MPEG-H 3D audio.

Spatial Relationship Descriptor (SRD) cuả MPEG-DASH cho phép mô tả media content được sắp xếp trong không gian như thế nào. Cụ thể, SRD được tích hợp một cách đầy đủ trong Media presentation description (MPD) của MPEG-DASH và sẽ được dùng để mô tả lưới (grid) các tile, điều này cho phép client có thể yêu cầu một vài khu vực quan trọng liên quan tới góc nhìn hiện tại - thường là một vài tile liền kề nhau - mà không phải là toàn bộ 360-degree. Điều thú vị là, SRD được phát triển trước cả OMAF và việc sử dụng SRD như thế nào hiện tại vẫn đang được xem xét.

**IEEE** đã bắt đầu dự án IEEE P2048: "P2048.2 Standard for Virtual Reality and Augmented Reality: Immersive Video Taxonomy and Quality Metrics" -- để định nghĩa các loại immersive video khác nhau -- và "P2048.3 Standard for Virtual Reality and Augmented Reality: Immersive Video File and Stream Formats" -- để định nghĩa format cho immersive video files và streams, các chức năng và interactions sẽ được xem xét trong formats. Đáng tiêc, không có nhiều báo cáo cụ thể được đưa ra. Dường như là, P2048.2 có liên quan tới QUALINET và P2048.3 sẽ tận dụng những gì MPEG đã và đang thực hiện (ví dụ MPEG-V). Ngoài ra, IEEE P3333.3 đưa ra một chuẩn cho công nghệ giảm mệt mỏi do xem video 3D (HMD based 3D content motion sickness reducing technology) nhằm giải quyết vấn đề về VR sickness qua các nghiên cứu về (i) phản ứng thị giác liên quan tới focal distortion, (ii) phản ứng thị giác liên quan đến lens materials, (iii) phản ứng thị giác liên quan tới lens refraction ratio, và (iv) phản ứng thị giác liên quan tới frame rate. 

**ITU-T** bắt đầu dự án "G.QoE-VR” sau khi kết thúc thành công dự án P.NATS, còn gọi là P.1203. Tuy nhiên cho đến nay, vẫn chưa có thông tin cụ thể về dự án "G.QoE-VR" được công bố rộng rãi. 

Cuối cùng, **Khronos group** đã công bố sáng kiến chuẩn VR, dẫn đến OpenXR (Cross-Platform, Portable, Virtual Reality), định nghĩa APIs cho VR/AR applications. Nó một lần nữa tận dụng các chuẩn của MPEG như là codecs, file format, và streaming format. Trong bối cảnh này, WebVR cũng đã định nghĩa các API có ich cho việc sử dụng VR devices, bao gồm sensor và head-mounted displays trên nền tảng web. 

Tóm lại, hầu hết các hoạt động định chuẩn hiện tại vẫn đang ở trong tình trạng sơ khai và chắc chắc là đáng để mọi người theo dõi.